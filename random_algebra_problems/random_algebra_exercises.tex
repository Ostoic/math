\documentclass[11pt]{article}
 
\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb}
\usepackage[utf8]{inputenc}

\include{algebra_commands}
\include{fundamental_commands}
 
\begin{document}
 
%\renewcommand{\qedsymbol}{\filledbox}
 
\title{Random Algebra/Number Theory Problems}
\author{Shaun Ostoic} 
 
\maketitle

\begin{exercise}{1}
Let $G$ be a finite group. Show that $a \in G$ is a generator of $G$ if and only if $a^{\frac{\order{G}}{q}} \neq 1$, for each prime factor $p$ of $\order{G}$.
\end{exercise}

\begin{proof}\necessary Since $a$ generates $G$, it is a cyclic group, hence $ G = \cyclic{a} $. A consequence of this is that $ \order{G} = \order{\cyclic{a}} = \order{a} $. Let us assume for sake of a contradiction, that $a^{\frac{\order{G}}{q}} = 1$ for some prime factor $ q $ of $ \order{G} $. Then we see that $ a^{\frac{\order{G}}{q}} = 1 \implies \order{a} \divides \frac{\order{G}}{q} \implies \order{a} = \order{G} < \frac{\order{G}}{q}$, which is a contradiction.

\sufficient Suppose instead that $ a $ is not a generator of $ G $. Then $\order{a} \neq \order{G} $, which means there must be a prime divisor $ q $ of $ \order{G} $ for which $ \order{a} \divides \frac{\order{G}}{q} $. To be more explicit, let us look at the prime factorization of $ \order{G} $ and of $ \order{a} $. Write $ \order{G} = q_{1}^{g_{1}} \dots q_{r}^{g_{r}}$ and $ \order{a} = q_{1}^{a_{1}} \dots q_{r}^{a_{r}}$, with $ a_{i} \leq g_{i} $ for all $ i $. It is entirely possible that $ a $ may hold each prime divsior of $ \order{G} $ in its prime factorization, but it does not necessarily have equal exponents in the factorization. Otherwise, $ a_{i} = g_{i} $ for all $ i $, hence $ \order{a} = \order{G} $. In this case, $ \order{a} $ and $ \order{G} $ must differ by at least one prime divisor $ q $. Then if we divide out that prime factor from $ \order{G} $, it follows that $ \order{a} \divides \frac{\order{G}}{q} $. By one of the previous theorems, this is equivalent to saying that $ a^{\frac{\order{G}}{q}} = 1 $, which contradicts the assumption we make in this direction of the proof.

\end{proof}

\begin{definition}{(Universal Exponent)}
A positive integer $ \lambda  $ is called the minimal universal exponent if $ \lambda $ is the smallest integer such that $ a^{\lambda} \equiv 1 \mod n$ for all residues $ a $ such that $ \gcd{a}{n} = 1$.
\end{definition}

\begin{lemma}{1} \label{lemma:1}
There exists a resiude of order $ \lambda $, where $ \lambda $ is the minimal universal exponent of $ p $.
\end{lemma}

\begin{exercise}{2}
Show that for any prime number $ p \geq 3 $, $ \Z_{p}^{*} $ has a primitive root.
\end{exercise}

\begin{proof}
To show that $ \Z_{p}^{*} $ has a primitive root, it is sufficient to show that $ \order{a} = \phi(p) = p-1 $, for some $ a \in \Z_{p}^{*} $. Let $ \lambda $ be the minimal universal exponent of $ p $. If $ \lambda = p-1 $, then there is a residue of order $ \lambda $ by Lemma (\ref{lemma:1}1), hence there is a primitive root. Otherwise, $ \lambda < p-1 $. In this case, there are at most $ \lambda $ solutions to the equation $ x^{\lambda} - 1 \equiv 0 \mod p$, by Lagrange's Polynomial Theorem. However, since $ a^{p-1} \equiv 1 \mod p $ for all nonzero residues $ a \in \Z_{p}^{*} $ (due to Fermat's Little Theorem), there are $ p-1 > \lambda$ solutions to the above polynomial, a contradiction. Therefore, $ \lambda = p - 1 $, which proves there is a resiude of order $ \phi(p) = p -1 $, hence there is a primitive root.

\end{proof}

\begin{exercise}{3}
Show that a finite subset $ B $ of a vector space $ V $ over a field $ F $ is a basis for $ V $ if and only if every $ v \in V $ can be written uniquely as a linear combination of vectors from $ B $. That is, where $ B = \{b_{1}, \ldots b_{n}\} $, the scalars $ \alpha_{i} \in F $ for all $ i $ are unique for which
\[ v = \alpha_{1} b_{1} + \ldots + \alpha_{n} b_{n}. \]

\end{exercise}

\begin{proof}
\necessary Suppose that $ B $ is a basis for $ V $. Then $ B $ is both a spanning set, and a linearly independent set. It is a spanning set for $ V $, which means that for every $ v \in V $, there exist scalars $ \alpha_{1}, \dots \alpha_{n} \in F $ such that 
\begin{equation} \label{eq:1}
	v = \alpha_{1} b_{1} + \dots + \alpha_{n} b_{n}.
\end{equation}
$ B $ being linearly independent means that if there exist $ \lin{\eta}{1}{n}{F} $ such that
\[ \eta_{1} b_{1} + \dots + \eta_{n} b_{n} = 0, \]
then  $ \eta_{i} = 0 $ for all $ i $.

We must now show that (\ref{eq:1}) is the only possible way to write $ v $ as a linear combination of vectors from $ B $. Suppose for sake of a contradiction that there is another such way to write $ v $, that being
\begin{equation} \label{eq:2}
	v = \beta_{1} b_{1} + \dots + \beta_{n} b_{n},	
\end{equation}
where $ \lin{\beta}{1}{n}{F} $. Using (\ref{eq:1}) and (\ref{eq:2}), we have
\[ \beta_{1} b_{1} + \dots + \beta_{n} b_{n} = \alpha_{1} b_{1} + \dots + \alpha_{n} b_{n} \]
\begin{equation} \label{eq:3}
	(\alpha_{1} - \beta_{1}) b_{1} + \dots + (\alpha_{n} - \beta_{n}) b_{n} = 0 
\end{equation}
Let us use the assumption that $ B $ is a linearly independent set. Set $ \eta_{i} = (\alpha_{i}-  \beta_{i}) $ for each $ i $. Then (\ref{eq:3}) can be written as 
\[ \eta_{1} b_{1} +  \dots + \eta_{n} b_{n} = 0, \]
which implies that $ \eta_{i} = 0 $ for all $ i $ by linear indepdendence of $ B $. That is, $ \alpha_{i} - \beta_{i} = 0 $, hence $ \alpha_{i} = \beta_{i} $ for all $ i $, which proves that these two ways of writing $ v $ are the same.

\sufficient Suppose that every $ v \in V $ can be written uniquely as a linear combination of vectors from $ B $. We must show that $ B $ is both a linearly independent set, and a spanning set for $ V $. First we show that it is a spanning set. Given any $ v \in V $, by assumption we can write 
\[ v = \alpha_{1}b_{1} + \dots + \alpha_{n} b_{n}, \] 
for some scalars $ \lin{\alpha}{1}{n}{F} $. We are done since this is the definition of $ B $ being a spanning set for $ V $. Last, to show that it is linearly independent, suppose there exist $ \alpha_{i} \dots \alpha_{n} \in F $, such that 
\[ \alpha_{1} b_{1} + \dots + \alpha_{n}b_{n} = 0. \]
This is also saying that 
\[ \alpha_{1} b_{1} + \dots + \alpha_{n}b_{n} = 0 \cdot b_{1} + \dots + 0 \cdot b_{n}, \]
which implies that $ \alpha_{i} = 0 $ for all $ i $. This is because we've assumed that there is only one such way to write this linear combination of vectors, hence $ B $ must be linearly independent. Therefore, $ B $ is a basis for $ V $.
\end{proof}

\begin{exercise}{4}
Let $ p $ be an odd prime and let $ k \geq 1 $.
\begin{enumerate}
	\item $ a $ is an odd primitive root modulo $ p^{k} \implies a $ is a primitive root modulo $ 2p^{k} $.
	\item $ a $ is an even primitive root modulo $ p^{k} \implies a + p^{k}$ is a primitive root modulo $ 2p^{k} $.
\end{enumerate}
\end{exercise}

\begin{proof}
\case{1} Assume $ a $ is an odd primitive root modulo $ p^{k} $. Then $ \phi(2p^{k})  = \phi(2) \phi(p^{k}) = \phi(p^{k})$. Suppose for sake of a contradiction that $ \order{a} < \phi(2 p^{k})$, and let $ m = \order{a} $. Then $ a^{m} \equiv 1 \mod 2 p^{k} $, hence 
$ a^{m} - 1 = 2 p^{k} \ell $ for some $ \ell $. If we bring the equation back into $ \Z^{*}_{p} $, we have $ a^{m} \equiv 1 \mod p^{k} $. However, we know that $ a $ is a primitive root modulo $ p^{k} $, so this contradicts the order of $ a $ being $ \phi(p^{k}) $. Thus, $ \order{a} = \phi(2p^{k}) $, which means $ a $ is also a primitive root modulo $ 2p^{k} $.

\case{2} Assume that $ a $ is an even primitive root modulo $ p^{k} $. To prove $ a + p^{k}$ is a primitive root modulo $ 2p^{k} $, assume it is not, for sake of a contradiction. Let $m =  \order{a + p^{k}} < \phi(2p^{k}) $, which leaves us with the congruences
\[ (a +p^{k})^{m} \equiv 1 \mod 2 p^{k}, \]
\[ (a + p^{k})^{m} - 1 = 2 p^{k} \ell, \]
\[ (a + p^{k})^{m} \equiv 1 \mod p^{k}, \]
for some $ \ell $. Observe by properties of congruences that
\[ a + p^{k} \equiv a \mod p^{k} \implies (a + p^{k})^{m} \equiv a^{m} \mod p^{k}. \]
Using the same technique as in \case{1} together with this observation yields $ a^{m} \equiv 1 \mod p^{k} $, where $ m < \phi(p^{k}) $. We initially assumed that $ a $ is a primitive root, meaning $ \order{a} = \phi(p^{k}) $, which is contradicted by this new deduction. Therefore, $ a + p^{k} $ must be a primitive root modulo $ 2p^{k} $.
\end{proof}

\begin{exercise}{5}
Let $ p $ be an odd prime number, and let $ a \in \Z_{p}^{*} $. Show that $ \order{a}  = q	 $, where $ q $ is a divisor of $ p-1 $, if and only if
\begin{enumerate}
	\item $ a^{q} \equiv 1 \mod p $
	\item $ a^{\frac{q}{r}} \equiv 1 \mod p$,
\end{enumerate}
where $ r $ is any prime divisor of $ q $.
\end{exercise}

\begin{proof}

\end{proof}

\begin{exercise}{8}
Define the concept of primitive root modulo $ p $, where $ p $is a prime number.
\end{exercise}

\begin{proof}[Solution]
A primitive root $ a $ modulo $ p $ is an element $ a \in \Z_{p}^{*} $ such that $ \order{a} = \phi(p) $. Equivalently, a primitive root $ a $ modulo $ p $ is an element such that every residue $ b \in \Z_{p}^{*} $ can be written as $ b \equiv a^{k} \mod p$ for some $ k \in \Z $.
\end{proof}

\begin{exercise}{9}
content...
\end{exercise}

\begin{exercise}{10}
Let $ p = 4q + 1$ be a prime number, where $ q $ is an odd prime. Show that $ 2 $ is a primitive root modulo $ p $.
\end{exercise}

\begin{proof}

\end{proof}

\begin{exercise}{10}
Discuss $ \Z_{m} $, for a positive integer $ m $.
\end{exercise}

\begin{proof}[Solution]
For an arbitrary positive integer $ m $, not every residue modulo $ m $ has an inverse, which is a desirable property for many applications. As such, finding a criterion for which $ \Z_{m} $ contains multiplicative inverses for each nonzero residue is an important venture. In general, any residue $ a \in \Z_{m} $ has a multiplicative inverse provided that $ \gcd{a}{m} = 1 $, and vice versa. From this point, one might ask what a residue system in which every nonzero residue has a multiplicative inverse. That is, given any residue $ a $, suppose $ \gcd{a}{m} = 1 $. The only such integers $ m $ for which $ \gcd{a}{m}  = 1 $for all $ a < m $ are the prime numbers. Thus, a residue system $ \Z_{m} $ is "complete", is a "field", contains multiplicative inverses, etc, if and only if $ m $ is prime.
\end{proof}

\begin{exercise}{12}
Define the characteristic of a ring $ R $.
\end{exercise}

\begin{proof}[Solution]
Given a unital ring $ R $ (a ring with $ 1 $), the characteristic $ n $ is the smallest positive integer such that $ 1 + 1 + \dots + 1 = 0 $ ($ n $ times ). That is, such that
$ \sum_{i = 1}^{n} 1 = 0$.
\end{proof}

\end{document}
	